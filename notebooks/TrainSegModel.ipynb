{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(\"../\")\n",
    "DATA = ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from box import ConfigBox\n",
    "from dvclive import Live\n",
    "from dvclive.fastai import DVCLiveCallback\n",
    "from fastai.data.all import Normalize, get_files\n",
    "from fastai.metrics import DiceMulti\n",
    "from fastai.vision.all import (Resize, SegmentationDataLoaders, aug_transforms,\n",
    "                               imagenet_stats, models, unet_learner)\n",
    "from ruamel.yaml import YAML\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split it into train/test\n",
    "\n",
    "We have some [data in DVC](https://dvc.org/doc/start/data-management/data-versioning) that we can pull. \n",
    "\n",
    "This data includes:\n",
    "* satellite images\n",
    "* masks of the swimming pools in each satellite image\n",
    "\n",
    "DVC can help connect your data to your repo, but it isn't necessary to have your data in DVC to start tracking experiments with DVC and DVCLive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pct = 0.25\n",
    "\n",
    "img_fpaths = get_files(DATA / \"pool_data\" / \"images\", extensions=\".jpg\")\n",
    "\n",
    "train_data_dir = DATA / \"train_data\"\n",
    "train_data_dir.mkdir(exist_ok=True)\n",
    "test_data_dir = DATA / \"test_data\"\n",
    "test_data_dir.mkdir(exist_ok=True)\n",
    "for img_path in img_fpaths:\n",
    "    msk_path = DATA / \"pool_data\" / \"masks\" / f\"{img_path.stem}.png\"\n",
    "    if np.random.uniform() <= test_pct:\n",
    "        shutil.copy(img_path, test_data_dir)\n",
    "        shutil.copy(msk_path, test_data_dir)\n",
    "    else:\n",
    "        shutil.copy(img_path, train_data_dir)\n",
    "        shutil.copy(msk_path, train_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data loader\n",
    "\n",
    "Load and prepare the images and masks by creating a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_path(x, train_data_dir):\n",
    "    return Path(train_data_dir) / f\"{Path(x).stem}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "valid_pct = 0.20\n",
    "img_size = 256\n",
    "\n",
    "data_loader = SegmentationDataLoaders.from_label_func(\n",
    "        path=train_data_dir,\n",
    "        fnames=get_files(train_data_dir, extensions=\".jpg\"),\n",
    "        label_func=partial(get_mask_path, train_data_dir=train_data_dir),\n",
    "        codes=[\"not-pool\", \"pool\"],\n",
    "        bs=bs,\n",
    "        valid_pct=valid_pct,\n",
    "        item_tfms=Resize(img_size),\n",
    "        batch_tfms=[\n",
    "            *aug_transforms(size=img_size),\n",
    "            Normalize.from_stats(*imagenet_stats),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review a sample batch of data\n",
    "\n",
    "Below are some examples of the images overlaid with their masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.show_batch(alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiple models with different learning rates using `DVCLiveCallback`\n",
    "\n",
    "Set up model training, using DVCLive to capture the results of each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(mask_pred, mask_true, classes=[0, 1], eps=1e-6):\n",
    "    dice_list = []\n",
    "    for c in classes:\n",
    "        y_true = mask_true == c\n",
    "        y_pred = mask_pred == c\n",
    "        intersection = 2.0 * np.sum(y_true * y_pred)\n",
    "        dice = intersection / (np.sum(y_true) + np.sum(y_pred) + eps)\n",
    "        dice_list.append(dice)\n",
    "    return np.mean(dice_list)\n",
    "\n",
    "def evaluate(learn):\n",
    "    test_img_fpaths = get_files(DATA / \"test_data\", extensions=\".jpg\")\n",
    "    test_dl = learn.dls.test_dl(test_img_fpaths)\n",
    "    preds, _ = learn.get_preds(dl=test_dl)\n",
    "    masks_pred = np.array(preds[:, 1, :] > 0.5, dtype=np.uint8)\n",
    "    test_mask_fpaths = [\n",
    "        get_mask_path(fpath, DATA / \"test_data\") for fpath in test_img_fpaths\n",
    "    ]\n",
    "    masks_true = [Image.open(mask_path) for mask_path in test_mask_fpaths]\n",
    "    dice_multi = 0.0\n",
    "    for ii in range(len(masks_true)):\n",
    "        mask_pred, mask_true = masks_pred[ii], masks_true[ii]\n",
    "        width, height = mask_true.shape[1], mask_true.shape[0]\n",
    "        mask_pred = np.array(\n",
    "            Image.fromarray(mask_pred).resize((width, height)),\n",
    "            dtype=int\n",
    "        )\n",
    "        mask_true = np.array(mask_true, dtype=int)\n",
    "        dice_multi += dice(mask_true, mask_pred) / len(masks_true)\n",
    "    return dice_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_arch = 'shufflenet_v2_x2_0'\n",
    "models_dir = ROOT / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "results_dir = ROOT / \"results\" / \"train\"\n",
    "\n",
    "for base_lr in [0.001, 0.005, 0.01]:\n",
    "    # initialize dvclive, optionally provide output path, and save results as a dvc experiment\n",
    "    with Live(str(results_dir), save_dvc_exp=True, report=\"notebook\") as live:\n",
    "        # log a parameter\n",
    "        live.log_param(\"train_arch\", train_arch)\n",
    "        fine_tune_args = {\n",
    "            'epochs': 8,\n",
    "            'base_lr': base_lr\n",
    "        }\n",
    "        # log a dict of parameters\n",
    "        live.log_params(fine_tune_args)\n",
    "\n",
    "        learn = unet_learner(data_loader, \n",
    "                            arch=getattr(models, train_arch), \n",
    "                            metrics=DiceMulti)\n",
    "        # train model and automatically capture metrics with DVCLiveCallback\n",
    "        learn.fine_tune(\n",
    "            **fine_tune_args,\n",
    "            cbs=[DVCLiveCallback(live=live)])\n",
    "\n",
    "        learn.export(fname=(models_dir / \"model.pkl\").absolute())\n",
    "\n",
    "        # add additional post-training summary metrics\n",
    "        live.summary[\"evaluate/dice_multi\"] = evaluate(learn)\n",
    "\n",
    "        # save model artifact to dvc\n",
    "        live.log_artifact(str(models_dir / \"model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare experiments\n",
    "!dvc exp show --only-changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review sample preditions vs ground truth\n",
    "\n",
    "Below are some example of the predicted masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=6, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review instances where loss function values are the highest (i.e. model is likely to be wrong)\n",
    "\n",
    "Below are the images, true masks, and predicted masks where loss was highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import SegmentationInterpretation\n",
    "\n",
    "interp = SegmentationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(k=5, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
